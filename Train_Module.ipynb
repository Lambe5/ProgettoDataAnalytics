{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'S0', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9',\n",
       "       'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19',\n",
       "       'S20', 'S21', 'S22', 'S23', 'S24', 'S25', 'S26', 'S27', 'S28', 'S29',\n",
       "       'S30', 'S31', 'S32', 'S33', 'S34', 'S35', 'S36', 'S37', 'S38', 'S39',\n",
       "       'S40', 'S41', 'S42', 'S43', 'S44', 'S45', 'S46', 'S47', 'S48', 'S49',\n",
       "       'S50', 'S51', 'S52', 'S53', 'S54', 'S55', 'S56', 'S57', 'S58', 'S59',\n",
       "       'S60', 'S61', 'S62', 'S63', 'S64', 'S65', 'S66', 'S67', 'S68', 'S69',\n",
       "       'S70', 'S71', 'S72', 'S73', 'S74', 'S75', 'S76', 'S77', 'S78', 'S79',\n",
       "       'S80', 'S81', 'S82', 'S83', 'S84', 'S85', 'S86', 'S87', 'S88', 'S89'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "FILENAME = \"train.csv\"\n",
    "df = pd.read_csv(FILENAME)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def my_train_test():\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df[[\"Year\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def my_train_validation_test():\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df[[\"Year\"]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    return(X_train, X_val, y_train, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def histogram(column_name):\n",
    "    data = X_train[column_name]\n",
    "    plt.hist(data)\n",
    "    plt.show()\n",
    "\n",
    "def all_histograms(df):\n",
    "    for col in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.hist(df[col], bins=20, color='skyblue', edgecolor='black')\n",
    "        plt.title(f'Istogramma della colonna {col}')\n",
    "        plt.xlabel('Valore')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "def boxplot_y():\n",
    "    data = y_train[\"Year\"]\n",
    "    plt.boxplot(data, whis=1.5)\n",
    "    plt.show()\n",
    "\n",
    "def density_plots(df):\n",
    "    for col in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.displot(df[col], kind=\"kde\", fill=True)\n",
    "        plt.title(f'Densità di probabilità della colonna {col}')\n",
    "        plt.xlabel('Valore')\n",
    "        plt.ylabel('Densità')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option(\"display.max_columns\", None)\n",
    "#pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "def plot_norm(x, x_normalized):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x_normalized)\n",
    "    plt.show()\n",
    "\n",
    "def norm(df, column_name, order):\n",
    "    x = df[column_name]\n",
    "    x_norm1 = np.linalg.norm(x, ord=order)\n",
    "    x_normalized = x / x_norm1\n",
    "    df[column_name] = x_normalized\n",
    "\n",
    "    if order == 1:\n",
    "        print(sum(x_normalized))\n",
    "    if order == 2:\n",
    "        print(sum(x_normalized**2))\n",
    "    if order == np.inf:\n",
    "        print(max(x_normalized))\n",
    "\n",
    "def min_max_sc(X_val = None):\n",
    "    #MinMax Scaling\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    min_max_scaler.fit(X_train)\n",
    "    X_train_minmax = min_max_scaler.transform(X_train)\n",
    "    X_test_minmax = min_max_scaler.transform(X_test)\n",
    "    if X_val is not None:\n",
    "        X_val_minmax = min_max_scaler.transform(X_val)\n",
    "        return (X_train_minmax, X_test_minmax, X_val_minmax)\n",
    "    else:\n",
    "        return (X_train_minmax, X_test_minmax)\n",
    "\n",
    "def standardization(X_val = None):\n",
    "    #Standardization\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    #Addestramento\n",
    "    scaler.fit(X_train)\n",
    "    #Applicazione\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    if X_val is not None:\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        return (X_train_scaled, X_test_scaled, X_val_scaled)\n",
    "    else:\n",
    "        return (X_train_scaled, X_test_scaled)\n",
    "\n",
    "X_train_norm1 = X_train.copy()\n",
    "X_train_norm2 = X_train.copy()\n",
    "X_train_normInf = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_minmax, X_test_minmax = min_max_sc()\n",
    "X_train_scaled, X_test_scaled = standardization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca(num_components, X_val_scaled = None):\n",
    "    pca = PCA(n_components=num_components)\n",
    "    principals_components_train = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "    # Trasforma il set di test utilizzando la stessa PCA addestrata sul set di addestramento\n",
    "    principals_components_test = pca.transform(X_test_scaled)\n",
    "\n",
    "    #loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i}' for i in range(1, len(X_train.columns) + 1)], index=X_train.columns)\n",
    "    #print(loadings)\n",
    "    if X_val_scaled is not None:\n",
    "        principals_components_val = pca.transform(X_val_scaled)\n",
    "        return (principals_components_train, principals_components_test, principals_components_val)\n",
    "    else:\n",
    "        return (principals_components_train, principals_components_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "principals_components_train, principals_components_test = pca(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calcola la media dei valori assoluti dei carichi per ciascun componente principale\n",
    "# mean_abs_loadings = loadings.abs().mean()\n",
    "\n",
    "# # Ordina i carichi in ordine decrescente di importanza\n",
    "# sorted_loadings = mean_abs_loadings.sort_values(ascending=False)\n",
    "\n",
    "# print(\"Componenti Principali più importanti:\")\n",
    "# print(sorted_loadings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calcola gli autovalori dall'oggetto PCA\n",
    "# eigenvalues = pca.explained_variance_\n",
    "\n",
    "# # Visualizza gli autovalori\n",
    "# print(\"Autovalori dei Componenti Principali:\")\n",
    "# for i, eig in enumerate(eigenvalues, 1):\n",
    "#     print(f\"PC{i}: {eig}\")\n",
    "\n",
    "# # Puoi anche visualizzarli in un grafico a barre per una migliore comprensione della distribuzione\n",
    "# plt.bar(range(1, len(eigenvalues) + 1), eigenvalues)\n",
    "# plt.xlabel('Componente Principale')\n",
    "# plt.ylabel('Autovalore')\n",
    "# plt.title('Autovalori dei Componenti Principali')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# # Considerando che principals_components è un array numpy con tre colonne\n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Estraiamo le colonne per l'asse x, y e z\n",
    "# x = principals_components_train[:, 0]\n",
    "# y = principals_components_train[:, 1]\n",
    "# z = principals_components_train[:, 2]\n",
    "\n",
    "# # Plot dello scatter tridimensionale\n",
    "# ax.scatter(x, y, z, c=y_train['Year'], marker='o')\n",
    "\n",
    "# # Etichette degli assi\n",
    "# ax.set_xlabel('Componente Principale 1')\n",
    "# ax.set_ylabel('Componente Principale 2')\n",
    "# ax.set_zlabel('Componente Principale 3')\n",
    "\n",
    "# plt.title('Scatter Plot dei Componenti Principali')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set a threshold for which features to extract\n",
    "# threshold = 0.3\n",
    "\n",
    "# # Find features with loadings above the threshold for each principal component\n",
    "# important_features = {}\n",
    "# for column in loadings.columns:\n",
    "#     important_features[column] = loadings.index[loadings[column].abs() > threshold].tolist()\n",
    "\n",
    "# # Now 'important_features' dictionary contains the important features for each PC\n",
    "# for pc, features in important_features.items():\n",
    "#     print(f\"{pc}: {', '.join(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a scree plot\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Explained variance ratio')\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate cumulative explained variance\n",
    "# cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# # Create a plot for cumulative explained variance\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "# plt.title('Cumulative Explained Variance')\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Cumulative explained variance')\n",
    "# plt.axhline(y=0.9, color='r', linestyle='-')  # 90% variance line\n",
    "# plt.text(0.5, 0.85, '90% cut-off threshold', color = 'red', fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def linearReg(X_train, y_train, X_test, y_test):\n",
    "    #Linear-Regressor\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    predizioni = reg.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predizioni)\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "    r_squared = r2_score(y_test, predizioni)\n",
    "    print(\"Coefficienti di determinazione R²:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 84.06098943629034\n",
      "Coefficienti di determinazione R²: 0.2305423370961881\n",
      "Mean Squared Error (MSE): 84.06098943629036\n",
      "Coefficienti di determinazione R²: 0.230542337096188\n",
      "Mean Squared Error (MSE): 84.06098943629036\n",
      "Coefficienti di determinazione R²: 0.230542337096188\n",
      "Mean Squared Error (MSE): 105.97465561853107\n",
      "Coefficienti di determinazione R²: 0.029954187000469146\n"
     ]
    }
   ],
   "source": [
    "linearReg(X_train, y_train, X_test, y_test)\n",
    "linearReg(X_train_minmax, y_train, X_test_minmax, y_test)\n",
    "linearReg(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "linearReg(principals_components_train, y_train, principals_components_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random-Forest-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def randomForest(X_train, y_train, X_test, y_test, n_alberi):\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=n_alberi, random_state=42)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "    rf_predictions = rf_regressor.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, rf_predictions)\n",
    "    r_squared = r2_score(y_test, rf_predictions)\n",
    "\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Coefficienti di determinazione R²:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomForest(principals_components_train, y_train, principals_components_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# n_estimators_values = [10, 50, 100, 200, 300]\n",
    "# mse_values = []\n",
    "\n",
    "# for n_estimators in n_estimators_values:\n",
    "#     modello_random_forest = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "    \n",
    "#     modello_random_forest.fit(X_train, y_train)\n",
    "    \n",
    "#     predizioni_val = modello_random_forest.predict(X_val)\n",
    "    \n",
    "#     mse_val = mean_squared_error(y_val, predizioni_val)\n",
    "    \n",
    "#     mse_values.append(mse_val)\n",
    "\n",
    "# # Plot dei risultati\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(n_estimators_values, mse_values, marker='o', linestyle='-')\n",
    "# plt.title('MSE al variare del numero di alberi nel RandomForestRegressor')\n",
    "# plt.xlabel('Numero di alberi')\n",
    "# plt.ylabel('MSE')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def svr(num_fold, X_train, y_train, X_test, y_test):\n",
    "    # Definisci la griglia dei parametri da testare\n",
    "    param_grid = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'C': [1, 10, 50, 100]\n",
    "    }\n",
    "\n",
    "    # Inizializza il regressore SVM\n",
    "    svm_regressor = SVR()\n",
    "\n",
    "    # Definisci il numero di fold per la cross-validation\n",
    "    num_folds = num_fold\n",
    "\n",
    "    # Inizializza il KFold\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Crea un oggetto GridSearchCV per trovare i migliori parametri con la k-fold cross-validation\n",
    "    grid_search = GridSearchCV(estimator=svm_regressor, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Esegui la cross-validation per trovare i migliori parametri\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Stampa i migliori parametri trovati\n",
    "    print(\"Migliori parametri:\", grid_search.best_params_)\n",
    "\n",
    "    # Valuta il modello con la migliore combinazione di parametri\n",
    "    best_svm_regressor = grid_search.best_estimator_\n",
    "\n",
    "    # Valuta il modello sui dati di test\n",
    "    y_pred = best_svm_regressor.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error sui dati di test:\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr(5, principals_components_train, y_train, principals_components_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def knn(num_neig, X_train, y_train, X_test, y_test):\n",
    "    neig = KNeighborsRegressor(n_neighbors=num_neig)\n",
    "    neig.fit(X_train, y_train)\n",
    "    y_pred = neig.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error sui dati di test:\", mse_test)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    print(\"Coefficienti di determinazione R²:\", r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, X_test, y_test = my_train_validation_test()\n",
    "X_train_scaled, X_test_scaled, X_val_scaled = standardization(X_val)\n",
    "principals_components_train, principals_components_test, principals_components_val = pca(5, X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cv(X_train, y_train, X_val, y_val):\n",
    "    # Definisci il range di iperparametri per il numero di vicini\n",
    "    param_grid = {'n_neighbors': np.arange(1, 21)}\n",
    "\n",
    "    # Inizializza il KNN Regressor\n",
    "    knn = KNeighborsRegressor()\n",
    "\n",
    "    # Inizializza la ricerca grid\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Estrai i risultati della ricerca grid\n",
    "    train_scores = np.sqrt(-grid_search.cv_results_['mean_train_score']) # Mean Squared Error sul train set\n",
    "    test_scores = np.sqrt(-grid_search.cv_results_['mean_test_score']) # Mean Squared Error sul test set\n",
    "    neighbors = param_grid['n_neighbors'] # Numero di vicini\n",
    "\n",
    "    # Plot dell'ampliamento dell'errore al variare del numero di vicini\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(neighbors, train_scores, label='Train Error', marker='o')\n",
    "    plt.plot(neighbors, test_scores, label='Validation Error', marker='o')\n",
    "    plt.xlabel('Number of Neighbors')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('KNN Regression - Validation Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Trova il miglior modello\n",
    "    best_neighbor = grid_search.best_params_['n_neighbors']\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Valida il miglior modello sul validation set\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    r_squared_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "    print(\"Miglior numero di vicini:\", best_neighbor)\n",
    "    print(\"Mean Squared Error sui dati di validation:\", mse_val)\n",
    "    print(\"Coefficienti di determinazione R² sui dati di validation:\", r_squared_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_cv(principals_components_train, y_train, principals_components_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed-Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelli deep per Tabular Data (TabNet &\n",
    "TabTransformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
