{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'S0', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9',\n",
       "       'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19',\n",
       "       'S20', 'S21', 'S22', 'S23', 'S24', 'S25', 'S26', 'S27', 'S28', 'S29',\n",
       "       'S30', 'S31', 'S32', 'S33', 'S34', 'S35', 'S36', 'S37', 'S38', 'S39',\n",
       "       'S40', 'S41', 'S42', 'S43', 'S44', 'S45', 'S46', 'S47', 'S48', 'S49',\n",
       "       'S50', 'S51', 'S52', 'S53', 'S54', 'S55', 'S56', 'S57', 'S58', 'S59',\n",
       "       'S60', 'S61', 'S62', 'S63', 'S64', 'S65', 'S66', 'S67', 'S68', 'S69',\n",
       "       'S70', 'S71', 'S72', 'S73', 'S74', 'S75', 'S76', 'S77', 'S78', 'S79',\n",
       "       'S80', 'S81', 'S82', 'S83', 'S84', 'S85', 'S86', 'S87', 'S88', 'S89'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "FILENAME = \"train.csv\"\n",
    "df = pd.read_csv(FILENAME)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def my_train_test():\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df[[\"Year\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def my_train_validation_test():\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df[[\"Year\"]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    return(X_train, X_val, y_train, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.iloc[:, 1:]\n",
    "# y = df[[\"Year\"]]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def histogram(column_name):\n",
    "    data = X_train[column_name]\n",
    "    plt.hist(data)\n",
    "    plt.show()\n",
    "\n",
    "def all_histograms(df):\n",
    "    for col in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.hist(df[col], bins=20, color='skyblue', edgecolor='black')\n",
    "        plt.title(f'Istogramma della colonna {col}')\n",
    "        plt.xlabel('Valore')\n",
    "        plt.ylabel('Frequenza')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "def boxplot_y():\n",
    "    data = y_train[\"Year\"]\n",
    "    plt.boxplot(data, whis=1.5)\n",
    "    plt.show()\n",
    "\n",
    "def density_plots(df):\n",
    "    for col in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.displot(df[col], kind=\"kde\", fill=True)\n",
    "        plt.title(f'Densità di probabilità della colonna {col}')\n",
    "        plt.xlabel('Valore')\n",
    "        plt.ylabel('Densità')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram(\"S10\") #Essendo un problema di regressione non direi che il seguente dataset risulta sbilanciato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_histograms(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#density_plots(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option(\"display.max_columns\", None)\n",
    "#pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "def plot_norm(x, x_normalized):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x_normalized)\n",
    "    plt.show()\n",
    "\n",
    "def norm(df, column_name, order):\n",
    "    x = df[column_name]\n",
    "    x_norm1 = np.linalg.norm(x, ord=order)\n",
    "    x_normalized = x / x_norm1\n",
    "    df[column_name] = x_normalized\n",
    "    #plot_norm(x, x_normalized)\n",
    "    if order == 1:\n",
    "        print(sum(x_normalized))\n",
    "    if order == 2:\n",
    "        print(sum(x_normalized**2))\n",
    "    if order == np.inf:\n",
    "        print(max(x_normalized))\n",
    "\n",
    "X_train_norm1 = X_train.copy()\n",
    "X_train_norm2 = X_train.copy()\n",
    "X_train_normInf = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax Scaling\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit(X_train)\n",
    "X_train_minmax = min_max_scaler.transform(X_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#Addestramento\n",
    "scaler.fit(X_train)\n",
    "#Applicazione\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "principals_components_train = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Trasforma il set di test utilizzando la stessa PCA addestrata sul set di addestramento\n",
    "principals_components_test = pca.transform(X_test_scaled)\n",
    "\n",
    "#loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i}' for i in range(1, len(X_train.columns) + 1)], index=X_train.columns)\n",
    "#print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calcola la media dei valori assoluti dei carichi per ciascun componente principale\n",
    "# mean_abs_loadings = loadings.abs().mean()\n",
    "\n",
    "# # Ordina i carichi in ordine decrescente di importanza\n",
    "# sorted_loadings = mean_abs_loadings.sort_values(ascending=False)\n",
    "\n",
    "# print(\"Componenti Principali più importanti:\")\n",
    "# print(sorted_loadings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calcola gli autovalori dall'oggetto PCA\n",
    "# eigenvalues = pca.explained_variance_\n",
    "\n",
    "# # Visualizza gli autovalori\n",
    "# print(\"Autovalori dei Componenti Principali:\")\n",
    "# for i, eig in enumerate(eigenvalues, 1):\n",
    "#     print(f\"PC{i}: {eig}\")\n",
    "\n",
    "# # Puoi anche visualizzarli in un grafico a barre per una migliore comprensione della distribuzione\n",
    "# plt.bar(range(1, len(eigenvalues) + 1), eigenvalues)\n",
    "# plt.xlabel('Componente Principale')\n",
    "# plt.ylabel('Autovalore')\n",
    "# plt.title('Autovalori dei Componenti Principali')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# # Considerando che principals_components è un array numpy con tre colonne\n",
    "# fig = plt.figure(figsize=(8, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Estraiamo le colonne per l'asse x, y e z\n",
    "# x = principals_components_train[:, 0]\n",
    "# y = principals_components_train[:, 1]\n",
    "# z = principals_components_train[:, 2]\n",
    "\n",
    "# # Plot dello scatter tridimensionale\n",
    "# ax.scatter(x, y, z, c=y_train['Year'], marker='o')\n",
    "\n",
    "# # Etichette degli assi\n",
    "# ax.set_xlabel('Componente Principale 1')\n",
    "# ax.set_ylabel('Componente Principale 2')\n",
    "# ax.set_zlabel('Componente Principale 3')\n",
    "\n",
    "# plt.title('Scatter Plot dei Componenti Principali')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set a threshold for which features to extract\n",
    "# threshold = 0.3\n",
    "\n",
    "# # Find features with loadings above the threshold for each principal component\n",
    "# important_features = {}\n",
    "# for column in loadings.columns:\n",
    "#     important_features[column] = loadings.index[loadings[column].abs() > threshold].tolist()\n",
    "\n",
    "# # Now 'important_features' dictionary contains the important features for each PC\n",
    "# for pc, features in important_features.items():\n",
    "#     print(f\"{pc}: {', '.join(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a scree plot\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Explained variance ratio')\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate cumulative explained variance\n",
    "# cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# # Create a plot for cumulative explained variance\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "# plt.title('Cumulative Explained Variance')\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Cumulative explained variance')\n",
    "# plt.axhline(y=0.9, color='r', linestyle='-')  # 90% variance line\n",
    "# plt.text(0.5, 0.85, '90% cut-off threshold', color = 'red', fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 84.06098943629034\n",
      "Coefficienti di determinazione R²: 0.2305423370961881\n"
     ]
    }
   ],
   "source": [
    "#Linear-Regressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "predizioni = reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predizioni)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "r_squared = r2_score(y_test, predizioni)\n",
    "print(\"Coefficienti di determinazione R²:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 84.06098943629036\n",
      "Coefficienti di determinazione R²: 0.230542337096188\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "predizioni = reg.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, predizioni)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "r_squared = r2_score(y_test, predizioni)\n",
    "print(\"Coefficienti di determinazione R²:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 84.06098943629036\n",
      "Coefficienti di determinazione R²: 0.230542337096188\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train_minmax, y_train)\n",
    "\n",
    "predizioni = reg.predict(X_test_minmax)\n",
    "\n",
    "mse = mean_squared_error(y_test, predizioni)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "r_squared = r2_score(y_test, predizioni)\n",
    "print(\"Coefficienti di determinazione R²:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 105.97394637881598\n",
      "Coefficienti di determinazione R²: 0.02996067907172928\n"
     ]
    }
   ],
   "source": [
    "# Addestra un regressore lineare utilizzando i componenti principali\n",
    "reg = LinearRegression()\n",
    "reg.fit(principals_components_train, y_train)\n",
    "\n",
    "# Fai previsioni sul set di test utilizzando il modello addestrato\n",
    "predictions = reg.predict(principals_components_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "print(\"Coefficienti di determinazione R²:\", r_squared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random-Forest-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1351: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 104.92268697201021\n",
      "Coefficienti di determinazione R²: 0.02996067907172928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(principals_components_train, y_train)\n",
    "rf_predictions = rf_regressor.predict(principals_components_test)\n",
    "mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_r_squared = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Coefficienti di determinazione R²:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# n_estimators_values = [10, 50, 100, 200, 300]\n",
    "# mse_values = []\n",
    "\n",
    "# for n_estimators in n_estimators_values:\n",
    "#     modello_random_forest = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "    \n",
    "#     modello_random_forest.fit(X_train, y_train)\n",
    "    \n",
    "#     predizioni_val = modello_random_forest.predict(X_val)\n",
    "    \n",
    "#     mse_val = mean_squared_error(y_val, predizioni_val)\n",
    "    \n",
    "#     mse_values.append(mse_val)\n",
    "\n",
    "# # Plot dei risultati\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(n_estimators_values, mse_values, marker='o', linestyle='-')\n",
    "# plt.title('MSE al variare del numero di alberi nel RandomForestRegressor')\n",
    "# plt.xlabel('Numero di alberi')\n",
    "# plt.ylabel('MSE')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Definisci la griglia dei parametri da testare\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "# Inizializza il regressore SVM\n",
    "svm_regressor = SVR()\n",
    "\n",
    "# Definisci il numero di fold per la cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Inizializza il KFold\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Crea un oggetto GridSearchCV per trovare i migliori parametri con la k-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=svm_regressor, param_grid=param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Esegui la cross-validation per trovare i migliori parametri\n",
    "grid_search.fit(principals_components_train, y_train)\n",
    "\n",
    "# Stampa i migliori parametri trovati\n",
    "print(\"Migliori parametri:\", grid_search.best_params_)\n",
    "\n",
    "# Valuta il modello con la migliore combinazione di parametri\n",
    "best_svm_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Valuta il modello sui dati di test\n",
    "y_pred = best_svm_regressor.predict(principals_components_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error sui dati di test:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed-Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelli deep per Tabular Data (TabNet &\n",
    "TabTransformer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
