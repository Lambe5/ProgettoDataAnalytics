{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.categorical_encoders import CategoricalEmbeddingTransformer\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import first_analysis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression(\n",
    "    regression_data,\n",
    "    multi_target,\n",
    "    continuous_cols,\n",
    "    categorical_cols,\n",
    "    continuous_feature_transform,\n",
    "    normalize_continuous_features,\n",
    "    target_range,\n",
    "    batch_size,\n",
    "    epoch,\n",
    "    num_heads,\n",
    "    num_attn_blocks\n",
    "):\n",
    "    (train, test, target) = regression_data\n",
    "    data_config = DataConfig(\n",
    "        target=target + [\"MedInc\"] if multi_target else target,\n",
    "        continuous_cols=continuous_cols,\n",
    "        categorical_cols=categorical_cols,\n",
    "        continuous_feature_transform=continuous_feature_transform,\n",
    "        normalize_continuous_features=normalize_continuous_features\n",
    "    )\n",
    "    input_embed_dim = num_heads * 4\n",
    "    model_config_params = {\n",
    "        \"task\": \"regression\",\n",
    "        \"input_embed_dim\": input_embed_dim,\n",
    "        \"num_attn_blocks\": num_attn_blocks,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"metrics\":[\"mean_absolute_percentage_error\",\"mean_absolute_error\",\"r2_score\"]\n",
    "    }\n",
    "    if target_range:\n",
    "        _target_range = []\n",
    "        for target in data_config.target:\n",
    "            _target_range.append(\n",
    "                (\n",
    "                    float(train[target].min()),\n",
    "                    float(train[target].max()),\n",
    "                )\n",
    "            )\n",
    "        model_config_params[\"target_range\"] = _target_range\n",
    "    model_config = TabTransformerConfig(**model_config_params)\n",
    "    trainer_config = TrainerConfig(\n",
    "        max_epochs= epoch,\n",
    "        checkpoints=None,\n",
    "        early_stopping=None,\n",
    "        accelerator=\"cpu\",\n",
    "        fast_dev_run=False,\n",
    "        batch_size= batch_size\n",
    "    )\n",
    "    optimizer_config = OptimizerConfig()\n",
    "\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "    )\n",
    "    #print(train[53])\n",
    "    tabular_model.fit(train=train)\n",
    "\n",
    "    result = tabular_model.evaluate(test)\n",
    "    #assert \"test_mean_squared_error\" in result[0].keys()\n",
    "    pred_df = tabular_model.predict(test)\n",
    "    assert pred_df.shape[0] == test.shape[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_Tab_tests(df_train, df_test, y_train, y_test):\n",
    "    ref_df_train = pd.DataFrame(df_train)\n",
    "    ref_df_test = pd.DataFrame(df_test)\n",
    " \n",
    "    ref_df_train.columns = ref_df_train.columns.astype(str)\n",
    "    ref_df_test.columns = ref_df_test.columns.astype(str)\n",
    " \n",
    "    ref_df_train['Year'] = y_train['Year']\n",
    "    ref_df_test['Year'] = y_test['Year']\n",
    "\n",
    "    lista = list(ref_df_train.columns)\n",
    "    lista_target_range = list(range(1900, 2024))\n",
    " \n",
    "    target_column = str(ref_df_train.columns[-1])\n",
    "   \n",
    "    return (ref_df_train, ref_df_test, lista, lista_target_range, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PROVARE CON DIVERSI DATASET\n",
    "X_train = np.load(\"./Datasets/Train_Val_Test/Scaled/X_train_scaled.npy\")\n",
    "X_val = np.load(\"./Datasets/Train_Val_Test/Scaled/X_val_scaled.npy\")\n",
    "y_train, y_val = first_analysis.load_df(\"./Datasets/Train_Val_Test/y_train.csv\", \"./Datasets/Train_Val_Test/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[:200]\n",
    "# X_val = X_val[:40]\n",
    "# y_train = y_train.head(200)\n",
    "# y_val = y_val.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df_train, ref_df_test, lista, lista_target_range, target_column = input_Tab_tests(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(5, 11))\n",
    "batch_size = list(range(50, 450, 50))\n",
    "num_heads = list(range(1, 6))\n",
    "num_attn_blocks = list(range(1, 6))\n",
    "\n",
    "results = []\n",
    "for j,batch in enumerate(batch_size):\n",
    "    for i,epoch in enumerate(epochs):\n",
    "        for k,heads in enumerate(num_heads):\n",
    "            for w,attn_blocks in enumerate(num_attn_blocks):\n",
    "                result = test_regression(regression_data=(ref_df_train, ref_df_test, [target_column]), multi_target = None,\n",
    "                    continuous_cols = lista,\n",
    "                    categorical_cols = [],\n",
    "                    continuous_feature_transform = None,\n",
    "                    normalize_continuous_features = False,\n",
    "                    target_range=True,\n",
    "                    batch_size=batch,\n",
    "                    epoch=epoch, \n",
    "                    num_heads = heads,\n",
    "                    num_attn_blocks = attn_blocks )\n",
    "                result[0][\"batch_size\"] = batch\n",
    "                result[0][\"epochs\"] = epoch\n",
    "                result[0][\"num_heads\"] = heads\n",
    "                result[0][\"num_attn_blocks\"] = attn_blocks\n",
    "                results.append(result)\n",
    "        #print(\"batch_size: %d / %d      epoch: %d / %d\"%(j,(len(batch_size)-1),i,(len(epochs)-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = [item[0] for item in results]\n",
    "\n",
    "df_res =pd.DataFrame(list_dict)\n",
    "df_res.to_csv(\"./df_Res_tabtransformer.csv\")\n",
    "\n",
    "df_res.sort_values([\"test_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(df_res['epochs'], df_res['test_mean_absolute_percentage_error'], c=df_res['batch_size'], cmap='Blues', s=100, label='loss', alpha=0.6, edgecolors='w')\n",
    "#plt.scatter(df_res['epochs'], df_res['test_mean_absolute_error'], c=df_res['batch_size'], cmap='Blues', s=200, label='MAE', alpha=0.6, edgecolors='w')\n",
    "#plt.scatter(df_res['epochs'], df_res['test_mean_absolute_percentage_error'], marker='o', label='MAPE')\n",
    "#plt.scatter(df_res['epochs'], df_res['test_r2_score'], marker='o', label='R2')\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('batch_Size')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Errore')\n",
    "plt.title('Variazione degli errori al variare delle epoche')\n",
    "plt.legend()\n",
    " \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLAVA MODELLO DOPO AVER TROVATO GLI IPERPARAMETRI MIGLIORI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
